diff --git a/README.md b/README.md
index 7b3395da41dddcaf67a3d19f62810dd54dbc481b..72071f99cde3503b2c76c589efced3c48be9d0b4 100644
--- a/README.md
+++ b/README.md
@@ -104,50 +104,51 @@ Work with any LLM via its web chat interface. Aider streamlines copy/pasting cod
 
 ```bash
 python -m pip install aider-install
 aider-install
 
 # Change directory into your codebase
 cd /to/your/project
 
 # DeepSeek
 aider --model deepseek --api-key deepseek=<key>
 
 # Claude 3.7 Sonnet
 aider --model sonnet --api-key anthropic=<key>
 
 # o3-mini
 aider --model o3-mini --api-key openai=<key>
 ```
 
 See the [installation instructions](https://aider.chat/docs/install.html) and [usage documentation](https://aider.chat/docs/usage.html) for more details.
 
 ## More Information
 
 ### Documentation
 - [Installation Guide](https://aider.chat/docs/install.html)
 - [Usage Guide](https://aider.chat/docs/usage.html)
+- [Architecture Overview](https://aider.chat/docs/architecture.html)
 - [Tutorial Videos](https://aider.chat/docs/usage/tutorials.html)
 - [Connecting to LLMs](https://aider.chat/docs/llms.html)
 - [Configuration Options](https://aider.chat/docs/config.html)
 - [Troubleshooting](https://aider.chat/docs/troubleshooting.html)
 - [FAQ](https://aider.chat/docs/faq.html)
 
 ### Community & Resources
 - [LLM Leaderboards](https://aider.chat/docs/leaderboards/)
 - [GitHub Repository](https://github.com/Aider-AI/aider)
 - [Discord Community](https://discord.gg/Y7X7bhMQFV)
 - [Blog](https://aider.chat/blog/)
 
 ## Kind Words From Users
 
 - *"My life has changed... Aider... It's going to rock your world."* — [Eric S. Raymond on X](https://x.com/esrtweet/status/1910809356381413593)
 - *"The best free open source AI coding assistant."* — [IndyDevDan on YouTube](https://youtu.be/YALpX8oOn78)
 - *"The best AI coding assistant so far."* — [Matthew Berman on YouTube](https://www.youtube.com/watch?v=df8afeb1FY8)
 - *"Aider ... has easily quadrupled my coding productivity."* — [SOLAR_FIELDS on Hacker News](https://news.ycombinator.com/item?id=36212100)
 - *"It's a cool workflow... Aider's ergonomics are perfect for me."* — [qup on Hacker News](https://news.ycombinator.com/item?id=38185326)
 - *"It's really like having your senior developer live right in your Git repo - truly amazing!"* — [rappster on GitHub](https://github.com/Aider-AI/aider/issues/124)
 - *"What an amazing tool. It's incredible."* — [valyagolev on GitHub](https://github.com/Aider-AI/aider/issues/6#issue-1722897858)
 - *"Aider is such an astounding thing!"* — [cgrothaus on GitHub](https://github.com/Aider-AI/aider/issues/82#issuecomment-1631876700)
 - *"It was WAY faster than I would be getting off the ground and making the first few working versions."* — [Daniel Feldman on X](https://twitter.com/d_feldman/status/1662295077387923456)
 - *"THANK YOU for Aider! It really feels like a glimpse into the future of coding."* — [derwiki on Hacker News](https://news.ycombinator.com/item?id=38205643)
 - *"It's just amazing. It is freeing me to do things I felt were out my comfort zone before."* — [Dougie on Discord](https://discord.com/channels/1131200896827654144/1174002618058678323/1174084556257775656)
diff --git a/aider/website/docs/architecture.md b/aider/website/docs/architecture.md
new file mode 100644
index 0000000000000000000000000000000000000000..fa81e5a41ace3b25310ae2bd7603c9f57cf44265
--- /dev/null
+++ b/aider/website/docs/architecture.md
@@ -0,0 +1,72 @@
+---
+parent: More info
+nav_order: 470
+description: Overview of Aider's architecture and key components.
+---
+
+# Architecture Overview
+
+Aider is a command line tool that integrates large language models (LLMs) with local git repositories. It orchestrates the conversation with the LLM, applies edits to the working tree, and automatically commits changes. The design centers around a `Coder` class hierarchy which coordinates repository mapping, chat summarization and model interaction.
+
+```mermaid
+graph TD
+    A[aider.main] --> B[Coder.create]
+    B --> C[RepoMap]
+    B --> D[GitRepo]
+    B --> E[ChatSummary]
+    B --> F[InputOutput]
+    B --> G[Model]
+    D --> H[gitpython]
+    F --> I[chat_history.md]
+```
+
+## Key modules
+
+- **CLI startup (`aider/main.py`)**
+  parses arguments, selects a model via onboarding, sets up git, and constructs the initial `Coder` instance.
+- **Coders (`aider/coders/`)**
+  manage prompts and apply edits. `base_coder.py` implements common behavior while specialized coders like `ArchitectCoder` or `AskCoder` provide different chat modes. `Coder.create()` picks a subclass based on the selected edit format.
+- **Git integration (`aider/repo.py`)**
+  wraps GitPython to stage files, generate diffs and create commits. `auto_commit()` summarizes edits and reports commit hashes in chat.
+- **Model management (`aider/models.py`)**
+  describes model metadata and integrates with `litellm` for API calls. Each model sets `max_chat_history_tokens` (about 1/16 of its context window) so chat history can be summarized before it grows too large.
+- **RepoMap (`aider/repomap.py`)**
+  summarizes important files and identifiers to provide targeted context to the model when editing a large repository.
+- **Chat history (`aider/chat_summary.py`)**
+  compactly summarizes older messages. A background thread is launched when the history exceeds `max_chat_history_tokens`.
+- **Onboarding (`aider/onboarding.py`)**
+  selects a default model from available API keys or triggers OpenRouter OAuth if none are found.
+
+## Prompt assembly
+
+`ChatChunks` groups system prompts, repo summaries, examples and conversation history before sending messages to the model. Certain segments are marked as cacheable so providers can reuse them across requests.
+
+Specialized coders adjust the prompts and workflow. For example, architect mode first generates high level instructions with an architect model and then applies edits with the main model. The edit format controls how diffs or whole files are returned.
+
+## Memory and cost management
+
+Aider monitors token usage on every request. If a message would exceed the model's context window, the user is warned and chat history is summarized. The total tokens and estimated cost are tracked for the session. With `--restore-chat-history`, prior conversations from `chat_history.md` are loaded and summarized when Aider starts so context is retained across sessions.
+
+## Git workflow
+
+Aider edits the working tree directly. If `--auto-commit` is enabled, each batch of edits is automatically committed with a message generated by the model. The commit includes optional attribution trailers so it is clear which changes were made by Aider. Users can revert or inspect diffs using normal git commands.
+
+## Further reading
+
+- The [usage guide](usage.html) explains the basic workflow.
+- The [git integration](git.html) page details how commits are created.
+- The [edit formats](more/edit-formats.html) page describes the formats supported by different models.
+
+## In-depth topics
+
+The rest of the architecture documentation lives in the `architecture/` subdirectory:
+
+- [Coder hierarchy](architecture/coder-hierarchy.html)
+- [CLI and command system](architecture/cli-and-commands.html)
+- [Memory and context management](architecture/memory-and-context.html)
+- [Session resumption](architecture/resumption.html)
+- [Git workflow](architecture/git-workflow.html)
+- [Infinite output](architecture/infinite-output.html)
+- [Voice and help modules](architecture/voice-help.html)
+- [File watching](architecture/watch-files.html)
+- [Edit formats](architecture/edit-formats.html)
diff --git a/aider/website/docs/architecture/cli-and-commands.md b/aider/website/docs/architecture/cli-and-commands.md
new file mode 100644
index 0000000000000000000000000000000000000000..d3093f03853543306792d75285ad363462abff1a
--- /dev/null
+++ b/aider/website/docs/architecture/cli-and-commands.md
@@ -0,0 +1,26 @@
+---
+parent: Architecture Overview
+nav_order: 110
+---
+
+# CLI Entry Point and Commands
+
+The `aider.main` module is the program entry point.  It parses command‑line arguments using `ConfigArgParse` (`aider/args.py`), sets up colors and logging, discovers the git root, and selects an initial model via `onboarding.select_default_model`.
+
+```python
+args = parse_args(sys.argv[1:])
+model = select_default_model(args, io, analytics)
+coder = Coder.create(main_model=model, edit_format=args.edit_format, io=io, ...)
+```
+
+If `--watch-files` or `--copy-paste` is specified, the CLI attaches a `FileWatcher` or `ClipboardWatcher` so changes in your editor or clipboard can interrupt the prompt and send new instructions.
+
+The command system lives in `aider/commands.py`.  `Commands.get_commands()` registers built‑in commands (such as `/add`, `/commit`, `/undo`, `/chat-mode`) and provides tab completion support.  Custom front ends – including the optional browser UI or GUI wrappers – use the same command objects, so new interfaces can be layered on without changing the core coder logic.
+
+During an interactive session, `Coder.run()` repeatedly calls `Coder.get_input()` to retrieve user commands or plain text messages.  The prompt can be interrupted by:
+
+- `Control‑C` – handled in `base_coder.keyboard_interrupt()` which cancels the current LLM request and preserves pending edits.
+- File or clipboard watchers – these call `IO.interrupt_input()` which stores any partially typed input and returns control to the main loop.
+
+Both terminal and GUI/browser interfaces rely on this input loop, so adding a new front end primarily involves wiring its input and output streams into the `InputOutput` class.
+
diff --git a/aider/website/docs/architecture/coder-hierarchy.md b/aider/website/docs/architecture/coder-hierarchy.md
new file mode 100644
index 0000000000000000000000000000000000000000..066c3d48efcb8f221c949767f2b6d11113e5f67a
--- /dev/null
+++ b/aider/website/docs/architecture/coder-hierarchy.md
@@ -0,0 +1,51 @@
+---
+parent: Architecture Overview
+nav_order: 100
+---
+
+# Coder Hierarchy and Prompt Lifecycle
+
+Aider organizes its prompting logic around a set of `Coder` classes located in `aider/coders/`.  The base class `base_coder.py` manages common behavior such as tracking files in chat, running commands, and interacting with the LLM.  The `Coder.create()` factory picks an appropriate subclass based on the chosen edit format or chat mode.
+
+```
+aider/coders/
+├── base_coder.py
+├── ask_coder.py
+├── architect_coder.py
+├── patch_coder.py
+└── ...
+```
+
+Each subclass tailors the prompting strategy:
+
+- **AskCoder** – lightweight Q&A style interactions with minimal code editing.
+- **ArchitectCoder** – sends the user request to an architect model for high‑level planning and then forwards instructions to an editor model.
+- **PatchCoder**, **WholeCoder**, **DiffCoder** – return edits in the corresponding edit format.
+
+`Coder.create()` migrates chat history, open files, and other context when switching modes so the conversation continues smoothly.
+
+## Prompt Grouping
+
+`ChatChunks` (`aider/chat_chunks.py`) collects system messages, repo summaries, examples, read‑only files and prior chat history.  These are assembled into a consistent order before sending to the LLM:
+
+```python
+chunks.add_system(system_msg)
+chunks.add_examples(example_msgs)
+chunks.add_repo(repo_map)
+chunks.add_readonly(readonly_files)
+chunks.add_chat_files(in_chat_files)
+chunks.add_history(history_msgs)
+```
+
+Some chunks are marked cacheable, enabling providers that support prompt caching to reuse them.
+
+## Tool Calls and Multi‑step Replies
+
+Models can return tool calls (function calls in OpenAI style) to request additional files.  The coder parses these requests and replies with the relevant file contents before applying any edits.  Architect mode chains multiple models: the architect model replies with plain text instructions which are then passed to an editor coder that produces the final diff or whole‑file edits.
+
+```
+User → Architect model → instructions → Editor model → code edits
+```
+
+The coder also supports incremental output for models with the "infinite output" capability.  Partial responses are resent with `supports_assistant_prefill` so the model continues generating beyond its normal token limit.
+
diff --git a/aider/website/docs/architecture/edit-formats.md b/aider/website/docs/architecture/edit-formats.md
new file mode 100644
index 0000000000000000000000000000000000000000..2d1cb774c122fb99bd2e056f7704f769c6353963
--- /dev/null
+++ b/aider/website/docs/architecture/edit-formats.md
@@ -0,0 +1,13 @@
+---
+parent: Architecture Overview
+nav_order: 180
+---
+
+# Edit Formats
+
+Aider supports several ways for the LLM to express code changes.  The main ones are `whole`, `diff`, `diff-fenced`, and `udiff`.  Each `Model` declares its preferred format in `models.yml`.  The CLI option `--edit-format` can override this choice.
+
+At runtime `Coder.create()` inspects the requested format and picks the appropriate subclass (`WholeCoder`, `DiffCoder`, etc.).  The prompts for each format live in `aider/prompts/*`.
+
+For details on the syntax of each format see [Edit formats](../more/edit-formats.html).
+
diff --git a/aider/website/docs/architecture/git-workflow.md b/aider/website/docs/architecture/git-workflow.md
new file mode 100644
index 0000000000000000000000000000000000000000..6ab19313c421ffbcab7adcfc8161ee3bc73e59b3
--- /dev/null
+++ b/aider/website/docs/architecture/git-workflow.md
@@ -0,0 +1,20 @@
+---
+parent: Architecture Overview
+nav_order: 140
+---
+
+# Git Integration and Auto‑Commit
+
+Git operations are handled by `aider/repo.py`.  `GitRepo` wraps GitPython to stage files, commit them, and generate diffs.  The coder passes `edited` filenames to `auto_commit()` which formats a commit message (sometimes via the LLM) and calls `GitRepo.commit()`.
+
+```python
+def commit(self, fnames=None, context=None, message=None, aider_edits=False, coder=None):
+    # Build commit message and set attribution
+    self.repo.index.add(fnames)
+    self.repo.index.commit(message, author=..., committer=...)
+```
+
+If `--auto-commit` is enabled, every successful edit cycle results in a commit.  The commit hash is reported back in the chat so the user can inspect or revert.  Manual `/commit` is available to checkpoint changes at any time.
+
+The repo map also relies on Git to list tracked files and to ignore paths described in `.gitignore` and `.aiderignore`.
+
diff --git a/aider/website/docs/architecture/infinite-output.md b/aider/website/docs/architecture/infinite-output.md
new file mode 100644
index 0000000000000000000000000000000000000000..1ccba11f0d241befd993e8a2238268017e75cfd4
--- /dev/null
+++ b/aider/website/docs/architecture/infinite-output.md
@@ -0,0 +1,18 @@
+---
+parent: Architecture Overview
+nav_order: 150
+---
+
+# Infinite Output Trick
+
+Models that support the `supports_assistant_prefill` capability can resume a reply after hitting the API's output token limit.  `base_coder.send_messages()` detects the `FinishReasonLength` exception and resends the partially generated text as a prefilled assistant message.  The model continues from that point, allowing Aider to gather arbitrarily long diffs.
+
+```python
+except FinishReasonLength:
+    self.multi_response_content = self.get_multi_response_content_in_progress()
+    messages[-1]['content'] = self.multi_response_content
+    # resend request with assistant_prefill
+```
+
+The collected fragments are joined heuristically before being applied to the working tree.  This trick enables large refactors even with strict output limits.
+
diff --git a/aider/website/docs/architecture/memory-and-context.md b/aider/website/docs/architecture/memory-and-context.md
new file mode 100644
index 0000000000000000000000000000000000000000..ba7371e4f0aa7ed899e5397899cf121a1404b7a8
--- /dev/null
+++ b/aider/website/docs/architecture/memory-and-context.md
@@ -0,0 +1,29 @@
+---
+parent: Architecture Overview
+nav_order: 120
+---
+
+# Memory and Context Management
+
+Aider must fit messages, repo summaries, and edits into the model's context window.  Each `Model` (from `aider/models.py`) specifies its max input tokens.  The coder computes `max_chat_history_tokens` as roughly one sixteenth of that size and triggers summarization when the conversation grows beyond this limit.
+
+## Summarizing Chat History
+
+`ChatSummary` (`aider/chat_summary.py`) runs in a background thread.  When launched via `Coder.summarize_start()`, it condenses `done_messages` into a shorter summary:
+
+```python
+def summarize_worker(self):
+    self.summarizing_messages = list(self.done_messages)
+    self.summarized_done_messages = self.summarizer.summarize(self.summarizing_messages)
+```
+
+After summarization finishes, the summary replaces the older messages so the coder can continue chatting without exceeding the token budget.  The total tokens sent and received are tracked for cost reporting.
+
+## Repository Map
+
+`RepoMap` (`aider/repomap.py`) generates concise summaries of files and their key symbols.  At runtime `Coder.get_repo_map()` selects only the most relevant portions based on the current conversation and `--map-tokens` budget.  This gives the model enough context to understand dependencies without exceeding the prompt limit.
+
+## Restoring History Across Sessions
+
+With the `--restore-chat-history` option, the markdown transcript from the previous run is read from `chat_history.md`.  The messages are loaded into `done_messages` on startup and summarized before the first prompt.  This allows long‑running projects to pick up where they left off even after the process exits.
+
diff --git a/aider/website/docs/architecture/resumption.md b/aider/website/docs/architecture/resumption.md
new file mode 100644
index 0000000000000000000000000000000000000000..091d408701a5977484e2727beac3030e8c4e9283
--- /dev/null
+++ b/aider/website/docs/architecture/resumption.md
@@ -0,0 +1,19 @@
+---
+parent: Architecture Overview
+nav_order: 130
+---
+
+# Session Resumption and Interrupt Handling
+
+Long running edits can be interrupted with `Control‑C`.  When the user sends the interrupt while a model reply is streaming, `base_coder.send_messages()` catches `KeyboardInterrupt` and stops waiting for the response.  The partial text already received stays in the conversation so you can clarify or retry.
+
+If a second `Control‑C` arrives within two seconds, `keyboard_interrupt()` exits immediately.  Otherwise it displays `^C again to exit` and returns to the input loop with any pending edits preserved.
+
+```python
+except KeyboardInterrupt:
+    interrupted = True
+    break
+```
+
+Aider also resumes gracefully if the process exits.  When `--restore-chat-history` is enabled, `InputOutput.read_text(chat_history_file)` loads the previous markdown transcript and `Coder.summarize_start()` condenses it to fit the new session's token budget.  Pending edits are stored in the git working tree; they will be committed on the next successful run.
+
diff --git a/aider/website/docs/architecture/voice-help.md b/aider/website/docs/architecture/voice-help.md
new file mode 100644
index 0000000000000000000000000000000000000000..3dbcbe9702e9b3e5e7d994b831c56a6f66eb4336
--- /dev/null
+++ b/aider/website/docs/architecture/voice-help.md
@@ -0,0 +1,17 @@
+---
+parent: Architecture Overview
+nav_order: 160
+---
+
+# Voice Input and Offline Help
+
+The `/voice` command uses `aider/voice.py` to record audio with the `sounddevice` library and transcribe it via `litellm.transcription` (currently OpenAI Whisper).  The resulting text is inserted into the chat as if the user had typed it.
+
+```python
+text = litellm.transcription(model="whisper-1", file=fh, prompt=history)
+```
+
+The `/help` command loads all markdown files from `aider/website` into a local vector search index (using `llama_index`).  Queries are matched against these documents and returned as context for the model.
+
+Both features are optional extras installed via `pip install aider-chat[voice]` or `[help]`.
+
diff --git a/aider/website/docs/architecture/watch-files.md b/aider/website/docs/architecture/watch-files.md
new file mode 100644
index 0000000000000000000000000000000000000000..148d8e758417e2dade618242e24968902e07fd2d
--- /dev/null
+++ b/aider/website/docs/architecture/watch-files.md
@@ -0,0 +1,19 @@
+---
+parent: Architecture Overview
+nav_order: 170
+---
+
+# File Watching Workflow
+
+The `FileWatcher` class (`aider/watch.py`) monitors the repository for lines ending with `AI!` or `AI?`.  When a change is detected, it sets `IO.interrupt_input()` so the main prompt loop stops waiting for user input and processes the request.
+
+```python
+changes = watch(*roots, watch_filter=self.filter_func, stop_event=self.stop_event)
+if self.handle_changes(changes):
+    return
+```
+
+`process_changes()` gathers all AI comments from tracked files and builds a consolidated instruction block.  If any comment ends with `AI!` the coder is asked to edit the code; if it ends with `AI?` the coder answers questions.  The watch mode is often enabled automatically in IDE integrations and can be used alongside clipboard watching.
+
+Corner cases include large files (ignored over 1MB) and paths filtered by `.gitignore` or `.aiderignore`.  The watcher runs on a background thread and can be stopped cleanly via `stop_event`.
+
